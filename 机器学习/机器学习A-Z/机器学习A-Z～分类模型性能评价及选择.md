# 机器学习A-Z～分类模型性能评价及选择

本篇文章将给大家介绍一些宏观的核心概念和测度来评价分类算法和分类器的表现，尤其是如何评价分类器预测中会产生的一些错误。

## 伪阳性(False Positives)和伪阴性(False Positives) 

首先讲的是伪阳性和伪阴性，英文叫做False Positives和False Negatives。先回到之前逻辑回归的例子，下图画出了sigmod函数，用来预测某件事情是否会发生，比如用户是否会购买产品。

![](https://leafw-blog-pic.oss-cn-hangzhou.aliyuncs.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-14%20%E4%B8%8A%E5%8D%8810.17.52.png)

我们把概率小于0.5的视作不会买，超过0.5的用户会购买。假设现在已知四个用户，13没有购买，24购买了。但我们依然可以用分类器去尝试预测结果。

![](https://leafw-blog-pic.oss-cn-hangzhou.aliyuncs.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-14%20%E4%B8%8A%E5%8D%8810.25.12.png)

我们将数据点投射到头像上，会发现有两种不同的错误，对于3号用户的错误，我们称作伪阳性，或者叫做1型错误，对于2号错误，称作伪阴性或者叫做2型错误。一般来说2型错误比1型错误要严重的多。比如判断艾滋病，假设如果我们判断一个没有疾病的人是阳性的，这个结果有一定的严重性，但会做再次的检测最终解决掉。但如果实际上是病毒携带者但判断成阴性，这个结果相对来说要严重的多，因为可能会耽误对疾病的治疗。

## 混淆矩阵(Confusion Matrix)

混淆矩阵在之前的文章有提及过，这里再大致解释一下。如下图所示，横轴指的是实际的值，纵轴是预测的值。

![混淆矩阵](https://leafw-blog-pic.oss-cn-hangzhou.aliyuncs.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-14%20%E4%B8%8A%E5%8D%8810.34.58.png)

35代表的就是实际值是0我们预测也是0的个数，50指的是实际1预测也是1的个数。显然这里也可以看出5代表伪阳性的个数，10代表伪阴性的个数。此时可以得到两个比值，一个是正确率即正确的判断个数35+50=85除以总的个数100，一个是错误的个数10+5=15除以总个数100。

### 准确率悖论

混淆矩阵中有时候这两个比值并不能说明太大的问题，有时候需要更加高级的方法评价分类器的好坏。来看看下面的矩阵：

![](https://leafw-blog-pic.oss-cn-hangzhou.aliyuncs.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-14%20%E4%B8%8A%E5%8D%8810.42.13.png)

很显然可以计算出正确率等于98%，这时是否能说明这个分类器的质量很好？现在我们给出一个新的分类方法，不管什么养的数据，都预测为0.就相当于右边一列的数字都加到左边一列中。现在再计算准确率，会发现准确率变成了98.5%。也就是说虽然用的方法很简单粗暴，但实际准确率却比前一个更好。这说明通过这种方式在这种情景下不适合判断分类的结果，需要使用其他更好的方法。

## 累计准确曲线(Cumulative Accuracy Profile)

上面的案例中可以看出通过混淆矩阵有时候不能很好的判断分类结果的质量，现在来看一个更加高级的判断方法，叫做累计准确曲线(CAP)。来看下面的例子，横走为我们联系的客户，纵轴为后买的客户数量。

![](https://leafw-blog-pic.oss-cn-hangzhou.aliyuncs.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-14%20%E4%B8%8A%E5%8D%8810.48.28.png)

那么这时可以得到一条直线，这些客户都是通过我们随机抽样联系的客户，随着抽样人数的增加，会购买的用户数量会逐渐变多。此时假设我们使用训练好的算法来判断用户是否会购买产品，得到预测的结果后，我们可以优先去联系预测结果是会购买产品的客户，这样我们刚开始联系的客户会有很大概率是会购买产品的，随着联系人数的增加，比如到了60000，预测剩下的人不会购买产品，此时从公司的角度出发实际上是可以不去联系这剩下的客户，因为他们购买的概率比较小。但这里为了完整画出曲线，还是继续画出后面的点。也就是说不管用什么样的模型，当我们完整的联系所有的客户群，也就是100000个客户，最后的点一定是重合的。

![](https://leafw-blog-pic.oss-cn-hangzhou.aliyuncs.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-14%20%E4%B8%8A%E5%8D%8810.54.42.png)

很显然这条曲线在之前的图像之上，因为我们使用了机器学习算法，使得公司的运营更加的有效率。这个模型越好，那么这个模型就会越凸。现在将横纵轴上的值变成百分比。横轴的100%指的是百分百的客户群，纵轴的100%指的是估算出的会购买的用户总数。

![](https://leafw-blog-pic.oss-cn-hangzhou.aliyuncs.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-14%20%E4%B8%8A%E5%8D%8811.00.49.png)

假设现在有另一个模型，没有红色的模型好。那么它可能的图像就会如上面绿色曲线。因为如果用更好的模型，那么某个点中实际上会购买的用户的量应该是比较靠上的。相对于之前的混淆矩阵，这是提供了更多的信息来判断模型的好坏。假设这时有个非常好的模型，我们称作做Crystal Ball，这个图像会是什么样子？我们之前随机抽样中知道10000中大约有10000个人会购买产品，也就是说有百分之十的人会购买，那么这个最好的模型就是一开始就找到这百分之十的人。

![](https://leafw-blog-pic.oss-cn-hangzhou.aliyuncs.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-14%20%E4%B8%8A%E5%8D%8811.03.38.png)

如上图黑色的线，在10%的位置就达到图像的顶点，后面是一条与横轴平行的直线。这种模型可以说是最完美的模型，几乎不可能达到的，所以叫做水晶球模型。如果我们有条曲线出现在蓝色的曲线下方的话，这说明这个模型非但没取到更好的预测效果，甚至不如一个随机的抽样，这是比较容易发现的。

除了CAP曲线，实际生活中，还有一种可能用到的曲线和其类似，叫做ROC(Receiver Operating Characteristic)，大家可以自行去查询资料。

那么我们知道上图中红色的曲线是越靠近完美曲线说明模型越好，现在来看看如何来量化这种好与不好。我们定义$a_P$表示完美曲线和蓝色曲线所包含的面积，定义$a_R$为自己机器学习模型和蓝色曲线的面积。此时再定义$AR=\frac{a_R}{a_P}$，则这个比值越接近1说明我们建立的模型效果越好。现在已经有一些统计学上的工具来计算这个比值。但自己手动计算或者用机器来计算都比较麻烦，那么现在提供一个简单的经验法则来判断模型的好坏。

这时要用到一个50%的阈值，就是在x轴上找到50%的点，看看在模型上的点y轴坐标是多少。通过这个点就能提供很好的信息。

![](https://leafw-blog-pic.oss-cn-hangzhou.aliyuncs.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202019-03-14%20%E4%B8%8A%E5%8D%8811.17.54.png)

如上图所示，我们将X的值划分不同的区间，当X的值坐落于不同区间时，给出不同的评价。由于随机模型它在50%的点达到了50%，则X<60%说明比随机好不了多少，则判定其是个特别差的模型。再好一点就是一个比较差的模型，继续往上就是好的模型，随着X的增大则这个模型越来越好。

但超过90%时，这个模型就好的夸张了，这时候要引起注意。这并不是我们想要的结果。第一种情况，如果有个自变量和因变量有着非常紧密的因果关系时，比如跟用户打电话的次数，这是有着非常强的因果关系，那么这个时候就需要把这个特征从我们的自变量中剔除。第二种情况就是过拟合，就是模型过多的注意到训练集中的噪音，这也是需要注意的。但也有一些情况坐落的大于90%是因为训练集质量非常高，或者说建的模型非常好。

## 分类算法总结

分类算法目前已经讲了6个，下面提供各个分类模型优劣的汇总于说明(此部分主要节选于于机器学习A-Z课程的第三部分小结)：

![](https://leafw-blog-pic.oss-cn-hangzhou.aliyuncs.com/2018-02-08_23-01-04-8bec66817894824d5fc8ea2951562eda.jpg)

对于不同的案例，如何选择模型，首先第一步判断线性还是非线性：

> - 假如是线性的问题，您应该选择逻辑回归（logistic regression）或者支持向量机SVM。
> - 假如是非线性的问题，您应该选择朴素贝叶斯（naive bayes），决策树（decision tree）或者是随机森林（random forest）。在接下来的课程中我们会讲到神经网络（neural network），也是一个十分强大的方法。

从实际操作的角度也有一些规则：

> - 假如您想要给最终预测概率进行排序，您应该选择逻辑回归（logistic regression）或是朴素贝叶斯（Naive Bayes）。举个例子：您想要预测不同客户购买某项产品的概率，并将这些概率从大到小进行排序，以便锁定目标客户群。在这样的情形下，如果您的问题是线性的，您应该运用逻辑回归（logistic regression）；假如您的问题是非线性的，您应该选择朴素贝叶斯（naive bayes）模型。
> - 假如您想要预测每一个客户属于哪一个划分（segment），您应该选择SVM。市场和客户群体的划分可以是已完成的市场调研或者集群分析（clustering）的结果。
> - 假如您想要非常直观地展示／阐述模型，那么决策树（Decision Tree）是最佳选择。
> - 假如您想要最好的模型的分类表现，并且不太在意模型的展示／阐述，那么随机森林（random forest）是不错的选择。

以上，就是对分类模型的性能评价及选择的相关基础知识点。